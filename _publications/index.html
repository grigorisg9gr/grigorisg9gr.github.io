---
layout: single
title: Publications
excerpt: "Publications"
share: false
collection: publications
redirect_to: "https://grigoris.ece.wisc.edu/"
---


<div id="top-publications">

<style>
.link1 {
  margin-right: 20px;
}
</style>


<a class="link1" href="#journal-papers">Journal papers</a>     <a class="link1" href="#workshop-papers">Workshop papers</a> 
</div>

<script>
        window.location.href = "https://grigoris.ece.wisc.edu/";
</script>


<h2 id="peer-reviewed-conferences">Peer-reviewed conference papers:</h2>
<ul>

<li><strong>Everything Everywhere All at Once: LLMs can In-Context Learn Multiple Tasks in Superposition.</strong>
    <div style="padding-left: 16px">
      <p>Zheyang Xiong, Ziyang Cai, John Cooper, Albert Ge, Vasilis Papageorgiou, Zack Sifakis, Angeliki Giannou, Ziqian Lin, Liu Yang, Saurabh Agarwal, <strong>Grigorios Chrysos</strong>,  Samet Oymak, Kangwook Lee, Dimitris Papailiopoulos<br>
      International Conference on Machine Learning (<em>ICML</em>), 2025; <strong>Spotlight</strong>. <br>
      <a style="color: white; text-decoration: none;" href="https://arxiv.org/abs/2410.05603"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;PDF</span></a><br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We uncover how LLMs perform multiple in-context learning tasks simultaneously, during a single call.</span></p> <!-- https://arxiv.org/abs/2410.05603 -->
    </div></li>

<li><strong>Certified Robustness Under Bounded Levenshtein Distance.</strong>
    <div style="padding-left: 16px">
      <p>Elias Abad Rocamora, <strong>Grigorios Chrysos</strong>, Volkan Cevher<br>
      International Conference on Learning Representations (<em>ICLR</em>), 2025. <br>
      <a style="color: white; text-decoration: none;" href="https://arxiv.org/abs/2501.13676"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;PDF</span></a>
      <a style="color: white; text-decoration: none;" href="https://github.com/LIONS-EPFL/LipsLev"><span class="buttong button-round"> <i class="fa fa-fw fa-github" aria-hidden="true"></i>&nbsp;Code</span></a><br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We propose a method for certifying the robustness of a convolutional text classifier through computing the Lipschitz constant with respect to the Levenshtein distance.</span></p> <!-- https://arxiv.org/abs/2501.13676 -->
    </div></li>

 <li><strong>Multilinear Mixture of Experts: Scalable Expert Specialization through Factorization.</strong>
    <div style="padding-left: 16px">
      <p>James Oldfield, Markos Georgopoulos, <strong>Grigorios Chrysos</strong>, Christos Tzelepis, Yannis Panagakis, Mihalis A. Nicolaou, Jiankang Deng, Ioannis Patras<br>
      Conference on Neural Information Processing Systems (<em>NeurIPS</em>), 2024. <br>
      <a style="color: white; text-decoration: none;" href="https://arxiv.org/pdf/2402.12550"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;PDF</span></a> 
      <a style="color: white; text-decoration: none;" href="https://github.com/james-oldfield/muMoE"><span class="buttong button-round"> <i class="fa fa-fw fa-github" aria-hidden="true"></i>&nbsp;Code</span></a>
      <a style="color: white; text-decoration: none;" href="https://james-oldfield.github.io/muMoE/"><span class="buttong button-round"> <i class="fa fa-fw fa-file-text-o" aria-hidden="true"></i>&nbsp;Project page</span></a> <br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We design an architecture that can scale the number of experts in Mixture-of-Expert architectures and we exhibit how this leads to specialization of the experts.</span></p> <!-- https://arxiv.org/abs/2402.12550 -->
    </div></li>


<li><strong>MIGS: Multi-Identity Gaussian Splatting via Tensor Decomposition.</strong>
    <div style="padding-left: 16px">
      <p>Aggelina Chatziagapi, <strong>Grigorios Chrysos</strong>, Dimitris Samaras<br>
      European Conference on Computer Vision (<em>ECCV</em>), 2024. <br>
      <a style="color: white; text-decoration: none;" href="https://arxiv.org/abs/2407.07284"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;PDF</span></a>
      <a style="color: white; text-decoration: none;" href="#"><span class="buttong button-round"> <i class="fa fa-fw fa-github" aria-hidden="true"></i>&nbsp;Code</span></a><br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We introduce a core block that learns a single neural representation for multiple identities, using only monocular videos in 3D Gaussian Splatting (3DGS).</span></p> <!-- https://arxiv.org/abs/2407.07284 -->
    </div></li>


<!---------------               ICML 2024                --------------->

<li><strong>Revisiting character-level adversarial attacks for Language Models.</strong>
    <div style="padding-left: 16px">
      <p>Elias Abad Rocamora, Yongtao Wu, Fanghui Liu, <strong>Grigorios Chrysos</strong>, Volkan Cevher<br>
      International Conference on Machine Learning (<em>ICML</em>), 2024. <br>
      <a style="color: white; text-decoration: none;" href="https://openreview.net/pdf/3ca014f375f8aa0572aad3f58b3d89bc2a2f80d7.pdf"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;PDF</span></a>
      <a style="color: white; text-decoration: none;" href="https://github.com/LIONS-EPFL/Charmer"><span class="buttong button-round"> <i class="fa fa-fw fa-github" aria-hidden="true"></i>&nbsp;Code</span></a><br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We introduce a character-level adversarial attack for text classifiers.</span></p> <!-- https://arxiv.org/abs/2405.04346 -->
    </div></li>


<li><strong>Going beyond compositional generalization, DDPMs can produce zero-shot interpolation.</strong>
    <div style="padding-left: 16px">
      <p>Justin Deschenaux, Igor Krawczuk, <strong>Grigorios Chrysos</strong>, Volkan Cevher<br>
      International Conference on Machine Learning (<em>ICML</em>), 2024. <br>
      <a style="color: white; text-decoration: none;" href="https://openreview.net/pdf/670b48719735353ec2924a4ef3d0a1cdb3d30749.pdf"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;PDF</span></a>
      <a style="color: white; text-decoration: none;" href="https://github.com/jdeschena/ddpm-zero-shot-interpolation"><span class="buttong button-round"> <i class="fa fa-fw fa-github" aria-hidden="true"></i>&nbsp;Code</span></a><br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We study the ability of diffusion models to generate samples beyond their training distribution focusing on the interpolation abilities.</span></p> <!-- https://arxiv.org/abs/2405.19201 -->
    </div></li>


<li><strong>Learning to Remove Cuts in Integer Linear Programming.</strong>
    <div style="padding-left: 16px">
      <p>Pol Puigdemont, Stratis Skoulakis, <strong>Grigorios Chrysos</strong>, Volkan Cevher<br>
      International Conference on Machine Learning (<em>ICML</em>), 2024. <br>
      <a style="color: white; text-decoration: none;" href="https://openreview.net/pdf?id=k10805cgak"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;PDF</span></a>
      <a style="color: white; text-decoration: none;" href="https://github.com/LIONS-EPFL/LearningToRemoveCutsILP"><span class="buttong button-round"> <i class="fa fa-fw fa-github" aria-hidden="true"></i>&nbsp;Code</span></a><br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We explore a new approach in solving integer linear programs (ILPs) with cutting plane methods: instead of only adding new cuts, we also consider the removal of previous cuts introduced at any of the preceding iterations of the method under a learnable parametric criteria.</span></p> <!-- https://arxiv.org/abs/2406.18781 -->
    </div></li>


<li><strong>REST: Efficient and Accelerated EEG Seizure Analysis through Residual State Updates.</strong>
    <div style="padding-left: 16px">
      <p>Arshia Afzal, <strong>Grigorios Chrysos</strong>, Volkan Cevher, Mahsa Shoaran<br>
      International Conference on Machine Learning (<em>ICML</em>), 2024. <br>
      <a style="color: white; text-decoration: none;" href="https://openreview.net/pdf?id=9GbAea74O6"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;PDF</span></a>
      <a style="color: white; text-decoration: none;" href="https://github.com/arshiaafzal/REST"><span class="buttong button-round"> <i class="fa fa-fw fa-github" aria-hidden="true"></i>&nbsp;Code</span></a>
      <a style="color: white; text-decoration: none;" href="https://arshiaafzal.github.io/REST/"><span class="buttong button-round"> <i class="fa fa-fw fa-file-text-o" aria-hidden="true"></i>&nbsp;Project page</span></a> <br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We introduce a graph-based architecture for real-time EEG signal analysis in epileptic seizure detection.</span></p> <!-- https://arxiv.org/abs/2406.16906 -->
    </div></li>

<!---------------         End of ICML 2024               --------------->



<!---------------               ICLR 2024                --------------->


<li><strong>Multilinear Operator Networks.</strong>
    <div style="padding-left: 16px">
      <p>Yixin Cheng, <strong>Grigorios Chrysos</strong>, Markos Georgopoulos, Volkan Cevher<br>
      International Conference on Learning Representations (<em>ICLR</em>), 2024. <br>
      <a style="color: white; text-decoration: none;" href="https://openreview.net/pdf?id=bbCL5aRjUx"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;PDF</span></a>
      <a style="color: white; text-decoration: none;" href="#"><span class="buttong button-round"> <i class="fa fa-fw fa-github" aria-hidden="true"></i>&nbsp;Code</span></a><br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We introduce a family of networks that rely on multilinear operations and capture high-degree interactions of the input elements. This family of networks, called MONet, performs on par with modern architectures on image recognition and beyond.</span></p> <!-- https://arxiv.org/pdf/2401.17992.pdf -->
    </div></li>


<li><strong>Generalization of Scaled Deep ResNets in the Mean-Field Regime.</strong>
    <div style="padding-left: 16px">
      <p>Yihang Chen, Fanghui Liu, Yiping Lu, <strong>Grigorios Chrysos</strong>, Volkan Cevher<br>
      International Conference on Learning Representations (<em>ICLR</em>), 2024. <br>
      <a style="color: white; text-decoration: none;" href="https://openreview.net/pdf?id=tMzPZTvz2H"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;PDF</span></a>
      <a style="color: white; text-decoration: none;" href="#"><span class="buttong button-round"> <i class="fa fa-fw fa-github" aria-hidden="true"></i>&nbsp;Code</span></a><br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We investigate the generalization properties of deep and wide ResNet models in the mean-field regime.</span></p> <!-- https://arxiv.org/pdf/2403.09889.pdf -->
    </div></li>


<li><strong>Robust NAS under adversarial training: benchmark, theory, and beyond.</strong>
    <div style="padding-left: 16px">
      <p>Yongtao Wu, Fanghui Liu, Carl-Johann Simon-Gabriel, <strong>Grigorios Chrysos</strong>, Volkan Cevher<br>
      International Conference on Learning Representations (<em>ICLR</em>), 2024. <br>
      <a style="color: white; text-decoration: none;" href="https://openreview.net/pdf?id=cdUpf6t6LZ"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;PDF</span></a>
		<a style="color: white; text-decoration: none;" href="https://github.com/TT2408/nasrobbench201"><span class="buttong button-round"> <i class="fa fa-fw fa-github" aria-hidden="true"></i>&nbsp;Code</span></a>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We release a benchmark for searching adversarially robust networks, while we also establish the generalization bounds for searched architectures under multi-objective adversarial training.</span></p> <!-- https://arxiv.org/pdf/2403.13134.pdf -->
    </div></li>

<li><strong>Efficient local linearity regularization to overcome catastrophic overfitting.</strong>
    <div style="padding-left: 16px">
      <p>Elias Abad Rocamora, Fanghui Liu, <strong>Grigorios Chrysos</strong>, Pablo Olmos, Volkan Cevher<br>
      International Conference on Learning Representations (<em>ICLR</em>), 2024. <br>
      <a style="color: white; text-decoration: none;" href="https://openreview.net/pdf?id=SZzQz8ikwg"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;PDF</span></a>
      <a style="color: white; text-decoration: none;" href="https://github.com/LIONS-EPFL/ELLE"><span class="buttong button-round"> <i class="fa fa-fw fa-github" aria-hidden="true"></i>&nbsp;Code</span></a><br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We propose a regularization term to mitigate catastrophic overfitting, which emerges in Single-step adversarial training.</span></p> <!-- https://arxiv.org/pdf/2401.11618.pdf -->
    </div></li>


<!---------------         End of ICLR 2024               --------------->

<li><strong>Maximum Independent Set: Self-Training through Dynamic Programming.</strong>
    <div style="padding-left: 16px">
      <p>Lorenzo Brusca*, Lars C.P.M. Quaedvlieg*, Stratis Skoulakis*, <strong>Grigorios Chrysos</strong>, Volkan Cevher<br>
      Conference on Neural Information Processing Systems (<em>NeurIPS</em>), 2023. <br>
      <a style="color: white; text-decoration: none;" href="https://openreview.net/pdf?id=igE3Zbxvws"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;PDF</span></a> 
      <a style="color: white; text-decoration: none;" href="https://github.com/LIONS-EPFL/dynamic-MIS"><span class="buttong button-round"> <i class="fa fa-fw fa-github" aria-hidden="true"></i>&nbsp;Code</span></a>
      <a style="color: white; text-decoration: none;" href="https://lions-epfl.github.io/dynamic-MIS/"><span class="buttong button-round"> <i class="fa fa-fw fa-file-text-o" aria-hidden="true"></i>&nbsp;Project page</span></a> <br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We design a framework for estimating the maximum independent set (MIS) without using supervised samples, inspired by dynamic programming.</span></p> <!-- https://arxiv.org/abs/2310.18672 -->
    </div></li>


<li><strong>On the Convergence of Encoder-Only Shallow Transformers.</strong>
    <div style="padding-left: 16px">
      <p>Yongtao Wu, Fanghui Liu, <strong>Grigorios Chrysos</strong>, Volkan Cevher<br>
      Conference on Neural Information Processing Systems (<em>NeurIPS</em>), 2023. <br>
      <a style="color: white; text-decoration: none;" href="https://arxiv.org/abs/2311.01575"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;PDF</span></a> <br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We study the convergence of shallow (single-block) transformers under different scalings and initializations using the realistic softmax-based transformer.</span></p> <!-- https://arxiv.org/abs/2311.01575 -->
    </div></li>


<li><strong>Benign Overfitting in Deep Neural Networks under Lazy Training.</strong>
    <div style="padding-left: 16px">
      <p>Zhenyu Zhu, Fanghui Liu, <strong>Grigorios Chrysos</strong>, Francesco Locatello, Volkan Cevher<br>
      International Conference on Machine Learning (<em>ICML</em>), 2023. <br>
      <a style="color: white; text-decoration: none;" href="https://openreview.net/pdf?id=LvT0l1CD81"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;PDF</span></a> <br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">In this work, we study the three interrelated concepts of overparameterization, benign overfitting, and the Lipschitz constant of DNNs and connect them in the lazy training regime.</span></p> <!-- https://arxiv.org/abs/2305.19377 -->
    </div></li>



<li><strong>Regularization of polynomial networks for image recognition.</strong>
    <div style="padding-left: 16px">
      <p><strong>Grigorios Chrysos</strong>, Bohan Wang, Jiankang Deng, Volkan Cevher<br>
      Computer Vision and Pattern Recognition Conference (<em>CVPR</em>), 2023. <br>
      <a style="color: white; text-decoration: none;" href="https://openaccess.thecvf.com/content/CVPR2023/papers/Chrysos_Regularization_of_Polynomial_Networks_for_Image_Recognition_CVPR_2023_paper.pdf"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;PDF</span></a> <br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We demonstrate how polynomial networks (without elementwise activation functions) can benefit from regularization schemes to reach the performance of standard neural networks. Then, we introduce a new class of polynomial networks that achieve even higher degree of expansions by using these additional regularization schemes.</span></p> <!-- http://arxiv.org/abs/2303.13896 -->
    </div></li>



<!---------------               NeurIPS 2022               --------------->
<li><strong>Robustness in deep learning: The good (width), the bad (depth), and the ugly (initialization).</strong>
    <div style="padding-left: 16px">
      <p>Zhenyu Zhu, Fanghui Liu, <strong>Grigorios Chrysos</strong>, Volkan Cevher<br>
      Conference on Neural Information Processing Systems (<em>NeurIPS</em>), 2022. <br>
      <a style="color: white; text-decoration: none;" href="https://openreview.net/pdf?id=m8vzptcFKsT"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;PDF</span></a> <br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We explore the interplay of the width, the depth and the initialization(s) on the average robustness of neural networks with both theoretical bounds and empirical validation.</span></p> <!-- https://arxiv.org/pdf/2209.07263.pdf https://openreview.net/pdf?id=m8vzptcFKsT -->
<!--  # # This works, but this only shows when hovering the citation. Perhaps modify it to show the summary when hovering. In addition, the citation should be copiable. 
            <style>
                .citation-container {
                    position: relative;
                    display: inline-block;
                }
        
                .my-hover-target {
                    cursor: pointer;
                    color: blue;
                    text-decoration: underline;
                }
        
                .bibtex-widget {
                    display: none;
                    position: absolute;
                    background: white;
                    border: 1px solid #ccc;
                    padding: 10px;
                    border-radius: 4px;
                    box-shadow: 0 2px 5px rgba(0,0,0,0.2);
                    width: 400px;
                    top: 100%;
                    left: 0;
                    z-index: 1000;
                    font-family: monospace;
                    white-space: pre-wrap;
                }

                /* Add this for notification when copying the bibtex */
                .copy-feedback {
                    display: none;
                    position: absolute;
                    background: #4CAF50;
                    color: white;
                    padding: 5px 10px;
                    border-radius: 3px;
                    font-size: 12px;
                }

            </style>
        <div class="citation-container">
           <span class="buttong button-round"><div class="my-hover-target">Copy bibtex citation.</div></span>
           <div class="bibtex-widget">@inproceedings{zhu2022robustness,
                    title={Robustness in deep learning: The good (width), the bad (depth), and the ugly (initialization)},
                    author={Zhu, Zhenyu and Liu, Fanghui and Chrysos, G Grigorios and Cevher, Volkan},
                    booktitle={Advances in neural information processing systems (NeurIPS)},
                    year={2022}
          }</div>
        </div>
            <script>
                document.addEventListener('DOMContentLoaded', function() {
                    const hoverElement = document.querySelector('.my-hover-target');
                    const bibtexWidget = document.querySelector('.bibtex-widget');
        
                    hoverElement.addEventListener('mouseover', function() {
                        bibtexWidget.style.display = 'block';
                    });
        
                    hoverElement.addEventListener('mouseout', function() {
                        bibtexWidget.style.display = 'none';
                    });
                });
            </script>
    </div></li>-->




<li><strong>Generalization Properties of NAS under Activation and Skip Connection Search.</strong>
    <div style="padding-left: 16px">
      <p>Zhenyu Zhu, Fanghui Liu, <strong>Grigorios Chrysos</strong>, Volkan Cevher<br>
      Conference on Neural Information Processing Systems (<em>NeurIPS</em>), 2022. <br>
      <a style="color: white; text-decoration: none;" href="https://openreview.net/pdf?id=aQySSrCbBul"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;PDF</span></a> <br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">Using our theoretical guarantees of neural architecture search (NAS) under various activation functions and residual connections, we design an effective train-free algorithm for NAS.</span></p> <!-- https://arxiv.org/pdf/2209.07238.pdf -->
    </div></li>


<li><strong>Sound and Complete Verification of Polynomial Networks.</strong>
    <div style="padding-left: 16px">
      <p>Elias Abad Rocamora, Mehmet Fatih Sahin, Fanghui Liu, <strong>Grigorios Chrysos</strong>, Volkan Cevher<br>
      Conference on Neural Information Processing Systems (<em>NeurIPS</em>), 2022. <br>
      <a style="color: white; text-decoration: none;" href="https://openreview.net/pdf?id=gsdHDI-p6NI"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;PDF</span></a>
      <a style="color: white; text-decoration: none;" href="https://github.com/megaelius/PNVerification"><span class="buttong button-round"> <i class="fa fa-fw fa-github" aria-hidden="true"></i>&nbsp;Code</span></a><br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We propose a branch and bound algorithm for certifying polynomial networks against (adversarial) attacks.</span></p> <!-- https://arxiv.org/pdf/2209.07235.pdf -->
    </div></li>


<li><strong>Extrapolation and Spectral Bias of Neural Nets with Hadamard Product: a Polynomial Net Study.</strong>
    <div style="padding-left: 16px">
      <p>Yongtao Wu, Zhenyu Zhu, Fanghui Liu, <strong>Grigorios Chrysos</strong>, Volkan Cevher<br>
      Conference on Neural Information Processing Systems (<em>NeurIPS</em>), 2022. <br>
      <a style="color: white; text-decoration: none;" href="https://openreview.net/pdf?id=_cXUMAnWJJj"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;PDF</span></a> 
      <a style="color: white; text-decoration: none;" href="https://github.com/LIONS-EPFL/pntk"><span class="buttong button-round"> <i class="fa fa-fw fa-github" aria-hidden="true"></i>&nbsp;Code</span></a><br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We study the extrapolation and spectral bias of neural networks with Hadamard products from a neural tangent kernel perspective.</span></p> <!-- https://arxiv.org/pdf/2209.07736.pdf -->
    </div></li>


<!---------------         End of NeurIPS 2022               --------------->

<li><strong>Augmenting Deep Classifiers with Polynomial Neural Networks.</strong>
    <div style="padding-left: 16px">
      <p><strong>Grigorios Chrysos</strong>* Markos Georgopoulos*, Jiankang Deng, Jean Kossaifi, Yannis Panagakis, Anima Anandkumar<br>
      European Conference on Computer Vision (<em>ECCV</em>), 2022. <br>
      <a style="color: white; text-decoration: none;" href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136850682.pdf"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;PDF</span></a> <!-- https://arxiv.org/pdf/2104.07916.pdf -->
      <a style="color: white; text-decoration: none;" href="https://github.com/grigorisg9gr/polynomials-for-augmenting-NNs"><span class="buttong button-round"> <i class="fa fa-fw fa-github" aria-hidden="true"></i>&nbsp;Code</span></a><br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We express modern architectures (e.g., residual and non-local networks) in the form of different degree polynomials of the input. This enables us to design extensions of successful architectures that perform favorably in various benchmarks.</span></p>
    </div></li>


<li><strong>Cluster-guided Image Synthesis with Unconditional Models.</strong>
    <div style="padding-left: 16px">
      <p>Markos Georgopoulos, James Oldfield, <strong>Grigorios Chrysos</strong>, Yannis Panagakis<br>
      Computer Vision and Pattern Recognition Conference (<em>CVPR</em>), 2022. <br>
      <a style="color: white; text-decoration: none;" href="https://openaccess.thecvf.com/content/CVPR2022/papers/Georgopoulos_Cluster-Guided_Image_Synthesis_With_Unconditional_Models_CVPR_2022_paper.pdf"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;PDF</span></a><br> <!-- https://arxiv.org/pdf/2112.12911.pdf -->
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We study controllable generation in unsupervised GAN models by leveraging clusters in the representation space of the generator. We show that these clusters, which capture semantic attributes, can be used for conditioning the generator.</span></p>
    </div></li>

<li><strong>The Spectral Bias of Polynomial Neural Networks.</strong>
    <div style="padding-left: 16px">
      <p>Moulik Choraria, Leello Tadesse Dadi, <strong>Grigorios Chrysos</strong>, Julien Mairal, Volkan Cevher<br>
      International Conference on Learning Representations (<em>ICLR</em>), 2022. <br>
      <a style="color: white; text-decoration: none;" href="https://openreview.net/pdf?id=P7FLfMLTSEX"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;PDF</span></a><br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We study the spectral bias of polynomial networks and compare it with the spectral bias of standard neural nets using kernel approximations.</span></p>
    </div></li>

<li><strong>Controlling the Complexity and Lipschitz Constant improves Polynomial Nets.</strong>
    <div style="padding-left: 16px">
      <p>Zhenyu Zhu, Fabian Latorre, <strong>Grigorios Chrysos</strong>, Volkan Cevher<br>
      International Conference on Learning Representations (<em>ICLR</em>), 2022. <br>
      <a style="color: white; text-decoration: none;" href="https://openreview.net/pdf?id=dQ7Cy_ndl1s"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;PDF</span></a><br> 
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We provide sample complexity results and bounds on the Lipschitz constant of polynomial networks, which we use to construct a regularization scheme that improves the robustness against adversarial noise.</span></p>
    </div></li>

<li><strong>Conditional Generation Using Polynomial Expansions.</strong>
    <div style="padding-left: 16px">
      <p><strong>Grigorios Chrysos</strong>, Markos Georgopoulos, Yannis Panagakis<br>
      Conference on Neural Information Processing Systems (<em>NeurIPS</em>), 2021. <br>
      <a style="color: white; text-decoration: none;" href="https://proceedings.neurips.cc/paper/2021/file/ef0d3930a7b6c95bd2b32ed45989c61f-Paper.pdf"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;PDF</span></a> <!-- https://arxiv.org/pdf/2104.05077.pdf -->
      <a style="color: white; text-decoration: none;" href="https://github.com/grigorisg9gr/polynomial_nets_for_conditional_generation"><span class="buttong button-round"> <i class="fa fa-fw fa-github" aria-hidden="true"></i>&nbsp;Code</span></a><br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We propose a polynomial expansion with respect to two (or more) variables, which is applied to conditional image generation.</span></p>
    </div></li>


<li><strong>Poly-NL: Linear Complexity Non-local Layers with Polynomials.</strong>
    <div style="padding-left: 16px">
      <p>Francesca Babiloni, Ioannis Marras, Filippos Kokkinos, Jiankang Deng, <strong>Grigorios Chrysos</strong>, Stefanos Zafeiriou<br>
      International Conference on Computer Vision (ICCV), 2021. <br>
      <a style="color: white; text-decoration: none;" href="https://arxiv.org/pdf/2107.02859.pdf"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;PDF</span></a><br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We cast non-local blocks as special cases of third degree polynomial functions. In addition, we propose a new non-local block that builds on this polynomial perspective but has more efficient operations, i.e., we aim to retain the expressivity of non-local layers while maintaining a linear complexity.</span></p>
    </div></li>



<li><strong>Unsupervised Controllable Generation with Self-Training.</strong>
    <div style="padding-left: 16px">
      <p><strong>Grigorios Chrysos</strong>, Jean Kossaifi, Zhiding Yu, Anima Anandkumar<br>
      International Joint Conference on Neural Networks (IJCNN), 2021.<br>
      <a style="color: white; text-decoration: none;" href="https://arxiv.org/pdf/2007.09250.pdf"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;PDF</span></a>Oral.<br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We modify the GAN architecture to achieve interpretable generation without using any supervision.</span></p>
    </div></li>




<li><strong>Reconstructing the Noise Manifold for Image Denoising.</strong>
    <div style="padding-left: 16px">
      <p>Ioannis Marras, <strong>Grigorios Chrysos</strong>, Ioannis Alexiou, Gregory Slabaugh, Stefanos Zafeiriou<br>
      European Conference on Computer Vision (<em>ECCV</em>), 2020. <br>
      <a style="color: white; text-decoration: none;" href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123540596.pdf"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;PDF</span></a> <br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We propose learning the noise variance manifold along with typical image-to-image translation to obtain improved denoising.</span></p>
    </div></li>


<li><strong>Multilinear Latent Conditioning for Generating Unseen Attribute Combinations.</strong>
    <div style="padding-left: 16px">
      <p>Markos Georgopoulos, <strong>Grigorios Chrysos</strong>, Maja Pantic, Yannis Panagakis<br>
      International Conference on Machine Learning (<em>ICML</em>), 2020. <br>
      <a style="color: white; text-decoration: none;" href="http://proceedings.mlr.press/v119/georgopoulos20a/georgopoulos20a.pdf"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;PDF</span></a> <br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We extend conditional VAE to capture multiplicative interactions of the (annotated) attributes in the latent space. This enables generating images with unseen attribute combinations during training.</span></p>
    </div></li>




<li><strong>&Pi;-nets: Deep Polynomial Neural Networks.</strong>
    <div style="padding-left: 16px">
      <p><strong>Grigorios Chrysos</strong>, Stylianos Moschoglou, Giorgos Bouritsas, Yannis Panagakis, Jiankang Deng, Stefanos Zafeiriou<br>
      Computer Vision and Pattern Recognition Conference (<em>CVPR</em>), 2020. <br>
      <a style="color: white; text-decoration: none;" href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Chrysos_P-nets_Deep_Polynomial_Neural_Networks_CVPR_2020_paper.pdf"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;PDF</span></a> 
      <a style="color: white; text-decoration: none;" href="https://github.com/grigorisg9gr/polynomial_nets"><span class="buttong button-round"> <i class="fa fa-fw fa-github" aria-hidden="true"></i>&nbsp;Code</span></a> 
      <a style="color: white; text-decoration: none;" href="/polynomial-nets/"><span class="buttong button-round"> <i class="fa fa-fw fa-file-text-o" aria-hidden="true"></i>&nbsp;Blog post</span></a>  
      <a style="color: white; text-decoration: none;" href="https://youtu.be/5HmFSoU2cOw"><span class="buttong button-round"> <i class="fa fa-fw fa-file-movie-o" aria-hidden="true"></i>&nbsp;1-minute video</span></a> 
      <a style="color: white; text-decoration: none;" href="/files/publications/pi-net_cvpr_poster.pdf"><span class="buttong button-round"> <i class="fa fa-fw fa-file-text-o" aria-hidden="true"></i>&nbsp;Poster</span></a> <!-- Break --><br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We use a high-order polynomial expansion as a function approximation method. The unknown parameters of the polynomial (i.e., high-order tensors) are estimated using a collective tensor factorization.</span></p>
    </div></li>




<li><strong>Robust Conditional Generative Adversarial Networks.</strong>
    <div style="padding-left: 16px">
      <p><strong>Grigorios Chrysos</strong>, Jean Kossaifi, Stefanos Zafeiriou<br>
      International Conference on Learning Representations (<em>ICLR</em>), 2019.<br>
      <a style="color: white; text-decoration: none;" href="https://arxiv.org/pdf/1805.08657.pdf"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;PDF</span></a> 
      <a style="color: white; text-decoration: none;" href="https://github.com/grigorisg9gr/rocgan"><span class="buttong button-round"> <i class="fa fa-fw fa-github" aria-hidden="true"></i>&nbsp;Code</span></a>
      <a style="color: white; text-decoration: none;" href="/files/publications/RoCGAN_ICLR_poster.pdf"><span class="buttong button-round"> <i class="fa fa-fw fa-file-text-o" aria-hidden="true"></i>&nbsp;Poster</span></a> <!-- Break --><br><br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">The topic of conditional data generation task (e.g., super-resolution) is the focus of this work. We introduce a new pathway in the encoder-decoder generator to improve the synthesized image.</span></p>
    </div></li>




<li><strong>Surface Based Object Detection in RGBD Images.</strong>
    <div style="padding-left: 16px">
      <p>Siddhartha Chandra<em>, <strong>Grigorios Chrysos</strong></em>, Iasonas Kokkinos<br>
      British Machine Vision Conference (<em>BMVC</em>), 2015.<br>
      <a style="color: white; text-decoration: none;" href="https://hal.inria.fr/hal-01263930/document"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;PDF</span></a> Oral, acceptance rate: 7%.<br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We extend standard object detection pipelines by leveraging depth information and introducing viewpoint based mixture components.</span></p>
    </div></li>

</ul>




<a href="#top-publications">Return to the top</a>













<!-- *******************************************************************************************
     **********************                 JOURNAL PAPERS                ********************** 
     *******************************************************************************************
-->

<h2 id="journal-papers">Peer-reviewed journal papers:</h2>
<ul>

<li><strong>Hadamard product in deep learning: Introduction, Advances and Challenges.</strong>
    <div style="padding-left: 16px">
      <p><strong>Grigorios Chrysos</strong>, Yongtao Wu, Razvan Pascanu, Philip Torr, Volkan Cevher<br>
      IEEE Transactions on Pattern Analysis and Machine Intelligence (<em>T-PAMI</em>), 2025. (impact factor 2023: 20.8) <br>
      <a style="color: white; text-decoration: none;" href="https://ieeexplore.ieee.org/document/10965485"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;Paper</span></a> 
      <a style="color: white; text-decoration: none;" href="https://arxiv.org/abs/2504.13112"><span class="buttong button-round">Paper (open access)</span></a> <!-- Break --><br>

      <span style="color: #609999; font-size: 13px; line-height: 13px;">This survey systematically examines the Hadamard product in diverse machine learning applications, offering a unified view of this versatile and impactful architectural primitive. </span></p>
    </div></li>


<li><strong>Single-pass Detection of Jailbreaking Input in Large Language Models.</strong>
    <div style="padding-left: 16px">
      <p>Leyla Naz Candogan, Yongtao Wu, Elias Abad Rocamora, <strong>Grigorios Chrysos</strong>, Volkan Cevher<br>
      Transactions on Machine Learning Research (<em>TMLR</em>), 2025. <br>
      <a style="color: white; text-decoration: none;" href="https://openreview.net/forum?id=42v6I5Ut9a"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;PDF</span></a>
      <a style="color: white; text-decoration: none;" href="https://github.com/LIONS-EPFL/SPD"><span class="buttong button-round"> <i class="fa fa-fw fa-github" aria-hidden="true"></i>&nbsp;Code</span></a> <br> 
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We introduce a method for detecting jailbreaking inputs via the logit values in a single forward pass, which is computationally efficient and effective.</span></p>
    </div></li>



<li><strong>Federated Learning under Covariate Shifts with Generalization Guarantees.</strong>
    <div style="padding-left: 16px">
      <p>Ali Ramezani-Kebrya, Fanghui Liu, Thomas Pethick, <strong>Grigorios Chrysos</strong>, Volkan Cevher<br>
      Transactions on Machine Learning Research (<em>TMLR</em>), 2023. <br>
      <a style="color: white; text-decoration: none;" href="https://openreview.net/forum?id=wkecshlYxI"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;PDF</span></a>
      <a style="color: white; text-decoration: none;" href="https://github.com/LIONS-EPFL/Federated_Learning_Covariate_Shift_Code"><span class="buttong button-round"> <i class="fa fa-fw fa-github" aria-hidden="true"></i>&nbsp;Code</span></a> <br> 
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We focus on the aspect of federated learning when there are coavariate shifts, which is a realistic scenario in multiple cases. We derive both theoretical guarantees and demonstrate how this can work in imbalanced data settings.</span></p>
    </div></li>



<li><strong>Linear Complexity Self-Attention with 3rd Order Polynomials.</strong>
    <div style="padding-left: 16px">
      <p>Francesca Babiloni, Ioannis Marras, Filippos Kokkinos, Jiankang Deng, Matteo Maggioni, <strong>Grigorios Chrysos</strong>, Philip Torr, Stefanos Zafeiriou<br>
      IEEE Transactions on Pattern Analysis and Machine Intelligence (<em>T-PAMI</em>), 2023. (impact factor 2023: 20.8). <br>
      <a style="color: white; text-decoration: none;" href="https://ieeexplore.ieee.org/abstract/document/10076897"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;Paper</span></a><br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We cast self-attention (and non-local blocks) as special cases of third degree polynomial functions. In addition, we propose a new block that builds on this polynomial perspective but it is more computationally efficient, i.e., we aim to retain the expressivity of self-attention/non-local layers while maintaining a linear complexity.</span></p>
    </div></li>




<li><strong>Revisiting adversarial training for the worst-performing class.</strong>
    <div style="padding-left: 16px">
      <p>Thomas Pethick, <strong>Grigorios Chrysos</strong>, Volkan Cevher<br>
      Transactions on Machine Learning Research (<em>TMLR</em>), 2023. <br>
      <a style="color: white; text-decoration: none;" href="https://openreview.net/forum?id=wkecshlYxI"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;PDF</span></a>
      <a style="color: white; text-decoration: none;" href="https://github.com/LIONS-EPFL/class-focused-online-learning-code"><span class="buttong button-round"> <i class="fa fa-fw fa-github" aria-hidden="true"></i>&nbsp;Code</span></a> <br> 
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We propose a new training method called class focused online learning (CFOL) to reduce the gap between the top-performing and worst-performing classes in adversarial training, resulting in a min-max-max optimization formulation.</span></p>
    </div></li>


<!-- * * * * * * * * * *     Pi-nets, PAMI   * * * * * * * * * *  -->
<li><strong>Deep Polynomial Neural Networks.</strong>
    <div style="padding-left: 16px">
      <p><strong>Grigorios Chrysos</strong>, Stylianos Moschoglou, Giorgos Bouritsas, Jiankang Deng, Yannis Panagakis, Stefanos Zafeiriou<br>
      IEEE Transactions on Pattern Analysis and Machine Intelligence (<em>T-PAMI</em>), 2021. (impact factor 2023: 20.8) <br>
      <a style="color: white; text-decoration: none;" href="https://ieeexplore.ieee.org/document/9353253"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;Paper</span></a> 
      <a style="color: white; text-decoration: none;" href="https://arxiv.org/abs/2006.13026"><span class="buttong button-round">Paper (open access)</span></a> 
      <a style="color: white; text-decoration: none;" href="https://github.com/grigorisg9gr/polynomial_nets"><span class="buttong button-round"> <i class="fa fa-fw fa-github" aria-hidden="true"></i>&nbsp;Code</span></a> 
      <a style="color: white; text-decoration: none;" href="/polynomial-nets/"><span class="buttong button-round"> <i class="fa fa-fw fa-file-text-o" aria-hidden="true"></i>&nbsp;Blog post</span></a>  
      <a style="color: white; text-decoration: none;" href="https://youtu.be/5HmFSoU2cOw"><span class="buttong button-round"> <i class="fa fa-fw fa-file-movie-o" aria-hidden="true"></i>&nbsp;1-minute video</span></a> <!-- Break --><br>

      <span style="color: #609999; font-size: 13px; line-height: 13px;">We propose a new class of architectures that use polynomial expansions to approximate the target functions. We validate the proposed polynomial expansions (i.e. &Pi;-nets) in diverse experiments: data generation, data classifcation, face recognition and non-euclidean representation learning. </span></p>
    </div></li>
<!-- * * * * * * * * * *  end of Pi-nets, PAMI * * * * * * * * * * -->


<li><strong>Tensor Methods in Computer Vision and Deep Learning.</strong>
    <div style="padding-left: 16px">
      <p>Yannis Panagakis*, Jean Kossaifi*, <strong>Grigorios Chrysos</strong>, James Oldfield, Mihalis A. Nicolaou, Anima Anandkumar, Stefanos Zafeiriou<br>
      Proceedings of the IEEE, 2021. <br>
      <a style="color: white; text-decoration: none;" href="https://ieeexplore.ieee.org/document/9420085"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;Paper</span></a> 
      <a style="color: white; text-decoration: none;" href="https://github.com/tensorly/Proceedings_IEEE_companion_notebooks"><span class="buttong button-round"> <i class="fa fa-fw fa-github" aria-hidden="true"></i>&nbsp;Code</span></a> <br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We provide an in-depth review of tensors and tensor methods in the context of representation learning and deep learning, with a particular focus on computer vision applications.  We also provide jupyter notebooks with accompanying code.</span></p>
    </div></li>


<li><strong>Non-adversarial polynomial synthesis.</strong>
    <div style="padding-left: 16px">
      <p><strong>Grigorios Chrysos</strong>, Yannis Panagakis<br>
      Pattern Recognition Letters, 2020. <br>
      <a style="color: white; text-decoration: none;" href="https://www.sciencedirect.com/science/article/abs/pii/S0167865520304116"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;Paper</span></a> <br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We propose a decoder-only generator that uses a polynomial expansion to synthesize new images.</span></p>
    </div></li>



<li><strong>RoCGAN: Robust Conditional GAN.</strong>
    <div style="padding-left: 16px">
      <p><strong>Grigorios Chrysos</strong>, Jean Kossaifi, Stefanos Zafeiriou<br>
      International Journal of Computer Vision (<em>IJCV</em>), 2020. (impact factor 2019: 11.042) <br>
      <a style="color: white; text-decoration: none;" href="https://link.springer.com/article/10.1007/s11263-020-01348-5"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;Paper (open access)</span></a> 
      <a style="color: white; text-decoration: none;" href="https://github.com/grigorisg9gr/rocgan"><span class="buttong button-round"> <i class="fa fa-fw fa-github" aria-hidden="true"></i>&nbsp;Code</span></a><br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We leverage structure in the output domain of a conditional data generation task (e.g., super-resolution) to improve the synthesized image. We experimentally validate that this results in synthesized images more robust to noise. Extension of the conference paper.</span></p>
    </div></li>


<li><strong>Motion Deblurring of Faces.</strong>
    <div style="padding-left: 16px">
      <p><strong>Grigorios Chrysos</strong>, Paolo Favaro, Stefanos Zafeiriou<br>
      International Journal of Computer Vision (<em>IJCV</em>), 2019. (impact factor 2019: 11.042) <br>
      <a style="color: white; text-decoration: none;" href="https://link.springer.com/article/10.1007/s11263-018-1138-7"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;Paper (open access)</span></a> <br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We introduce a framework for tackling motion blur of faces. Our method simulates motion blur using averaging of video frames, while we collect a dataset that contains millions of such frames.</span></p>
    </div></li>

<li><strong>The Menpo Benchmark for Multi-pose 2D and 3D Facial Landmark Localisation and Tracking.</strong>
    <div style="padding-left: 16px">
      <p>Jiankang Deng, Anastasios Roussos, <strong>Grigorios Chrysos</strong>, Evangelos Ververas, Irene Kotsia, Jie Shen, Stefanos Zafeiriou<br>
      International Journal of Computer Vision (<em>IJCV</em>), 2019. (impact factor 2019: 11.042) <br>
      <a style="color: white; text-decoration: none;" href="https://link.springer.com/article/10.1007/s11263-018-1134-y"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;Paper (open access)</span></a> <br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">A semi-automatic framework is proposed for annotating challenging deformable images and videos.</span></p>
    </div></li>


<li><strong>A Comprehensive Performance Evaluation of Deformable Face Tracking ''In-the-Wild''.</strong>
    <div style="padding-left: 16px">
      <p><strong>Grigorios Chrysos</strong>, Epameinondas Antonakos, Patrick Snape, A. Asthana, Stefanos Zafeiriou<br>
      International Journal of Computer Vision (<em>IJCV</em>), 2018. (impact factor 2019: 11.042)<br>
      <a style="color: white; text-decoration: none;" href="https://link.springer.com/article/10.1007/s11263-017-0999-5"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;Paper (open access)</span></a> 
      <a style="color: white; text-decoration: none;" href="https://github.com/grigorisg9gr/robust_deformable_face_tracking"><span class="buttong button-round"> <i class="fa fa-fw fa-github" aria-hidden="true"></i>&nbsp;Code</span></a><br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We conduct a large-scale study of deformable face tracking `in-the-wild', i.e., with videos captured in unrestricted conditions.</span></p>
    </div></li>


<li><strong>IPST: Incremental Pictorial Structures for model-free Tracking of deformable objects.</strong>
    <div style="padding-left: 16px">
      <p><strong>Grigorios Chrysos</strong>, Epameinondas Antonakos, Stefanos Zafeiriou<br>
      IEEE Transactions on Image Processing (<em>TIP</em>), 2018. (impact factor 2019: 9.34)<br>
      <a style="color: white; text-decoration: none;" href="https://ieeexplore.ieee.org/document/8316962"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;Paper</span></a><br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We introduce incremental pictorial structures for tracking deformable (part-based) objects, e.g., human body parts or fiducial points in the face.</span></p>
    </div></li>


<li><strong>PD2T: Person-specific Detection, Deformable Tracking.</strong>
    <div style="padding-left: 16px">
      <p><strong>Grigorios Chrysos</strong>, Stefanos Zafeiriou<br>
      IEEE Transactions on Pattern Analysis and Machine Intelligence (<em>T-PAMI</em>), 2017. (impact factor 2023: 20.8)<br>
      <a style="color: white; text-decoration: none;" href="https://ieeexplore.ieee.org/abstract/document/8094942"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;Paper</span></a><br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We propose a framework for extracting object-specific statistics for tracking a (deformable) object.</span></p>
    </div></li>




</ul>




<a href="#top-publications">Return to the top</a>



<!-- *******************************************************************************************
     **********************                 WORKSHOP PAPERS               ********************** 
     *******************************************************************************************
-->

<h2 id="workshop-papers">Workshop papers:</h2>
<ul>



<li><strong>Self-Supervised Neural Architecture Search for Imbalanced Datasets.</strong>
    <div style="padding-left: 16px">
      <p>Aleksandr Timofeev, <strong>Grigorios Chrysos</strong>, Volkan Cevher<br>
      International Conference on Machine Learning Workshops (ICMLW), 2021.<br>
      <a style="color: white; text-decoration: none;" href="https://arxiv.org/pdf/2109.08580.pdf"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;PDF</span></a><br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We propose a neural architecture search (NAS) framework for real world tasks: (a) in the absence of labels, (b) in the presence of imbalanced datasets, (c) on a constrained computational budget.</span></p>
    </div></li>


<li><strong>Unsupervised Controllable Generation with Self-Training.</strong>
    <div style="padding-left: 16px">
      <p><strong>Grigorios Chrysos</strong>, Jean Kossaifi, Zhiding Yu, Anima Anandkumar<br>
      International Conference on Machine Learning Workshops (ICMLW), 2020.<br>
      <a style="color: white; text-decoration: none;" href="https://arxiv.org/pdf/2007.09250.pdf"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;PDF</span></a><br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We modify the GAN architecture to achieve interpretable generation without using any supervision.</span></p>
    </div></li>



<li><strong>The 3D Menpo Facial Landmark Tracking Challenge.</strong>
    <div style="padding-left: 16px">
      <p>Stefanos Zafeiriou*<em>, <strong>Grigorios Chrysos</strong>*</em>, Anastasios Roussos*, Evangelos Ververas, J. Deng, George Trigeorgis<br>
      International Conference on Computer Vision Workshops (ICCVW), 2017.<br>
      <a style="color: white; text-decoration: none;" href="https://openaccess.thecvf.com/content_ICCV_2017_workshops/papers/w36/Zafeiriou_The_3D_Menpo_ICCV_2017_paper.pdf"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;PDF</span></a><br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">The first large-scale dataset with 3D annotations of facial landmarkrs is introduced.</span></p>
    </div></li>


<li><strong>Deep Face Deblurring.</strong>
    <div style="padding-left: 16px">
      <p><strong>Grigorios Chrysos</strong>, Stefanos Zafeiriou<br>
      Computer Vision and Pattern Recognition Conference Workshops (CVPRW), 2017.<br>
      <a style="color: white; text-decoration: none;" href="https://openaccess.thecvf.com/content_cvpr_2017_workshops/w33/papers/Chrysos_Deep_Face_Deblurring_CVPR_2017_paper.pdf"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;PDF</span></a><br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">A method for face deblurring is proposed. The method utilizes weak supervision to guide the learning of the deep neural network.</span></p>
    </div></li>

<li><strong>The Menpo Facial Landmark Localisation Challenge.</strong>
    <div style="padding-left: 16px">
      <p>Stefanos Zafeiriou, George Trigeorgis, <strong>Grigorios Chrysos</strong>, J. Deng, Jie Shen<br>
      Computer Vision and Pattern Recognition Conference Workshops (CVPRW), 2017.<br>
      <a style="color: white; text-decoration: none;" href="https://openaccess.thecvf.com/content_cvpr_2017_workshops/w33/papers/Zafeiriou_The_Menpo_Facial_CVPR_2017_paper.pdf"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;PDF</span></a><br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">The first large-scale dataset with annotations of facial landmarkrs in both (semi-)frontal and profile poses is introduced.</span></p>
    </div></li>


<li><strong>The First Facial Landmark Tracking in-the-Wild Challenge: Benchmark and Results.</strong>
    <div style="padding-left: 16px">
      <p>Jie Shen, Stefanos Zafeiriou, <strong>Grigorios Chrysos</strong>, Jean Kossaifi, Georgios Tzimiropoulos, Maja Pantic<br>
      International Conference on Computer Vision Workshops (ICCVW), 2015.<br>
      <a style="color: white; text-decoration: none;" href="https://openaccess.thecvf.com/content_iccv_2015_workshops/w25/papers/Shen_The_First_Facial_ICCV_2015_paper.pdf"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;PDF</span></a><br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">The first large-scale dataset for facial landmark tracking is introduced.</span></p>
    </div></li>


<li><strong>Offline Deformable Face Tracking in Arbitrary Videos.</strong>
    <div style="padding-left: 16px">
      <p><strong>Grigorios Chrysos</strong>, Epameinondas Antonakos, Stefanos Zafeiriou, Patrick Snape<br>
      International Conference on Computer Vision Workshops (ICCVW), 2015.<br>
      <a style="color: white; text-decoration: none;" href="https://openaccess.thecvf.com/content_iccv_2015_workshops/w25/papers/Chrysos_Offline_Deformable_Face_ICCV_2015_paper.pdf"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;PDF</span></a><br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">We propose a framework that can extract object-specific statistics and can be used for tracking long sequences of videos.</span></p>
    </div></li>

</ul>



<h2 id="thesis">Thesis</h2>
<ul>

<li><strong>Polynomial function approximation and its application to deep generative models</strong>
    <div style="padding-left: 16px">
      <p><strong>Grigorios Chrysos</strong><br>
      PhD thesis, Imperial College London. <br>
      <a style="color: white; text-decoration: none;" href="https://doi.org/10.25560/90057"><span class="buttong button-round"> <i class="fa fa-file-pdf-o" aria-hidden="true"></i> &nbsp;PDF</span></a><br>
      <span style="color: #609999; font-size: 13px; line-height: 13px;">My PhD thesis, spanning my first work on polynomial networks and deep generative models.</span></p>
    </div></li>

</ul>


<a href="#top-publications">Return to the top</a>

